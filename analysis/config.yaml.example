# SIB Alert Analysis Configuration
# Copy to config.yaml and customize

analysis:
  # Enable/disable AI-powered alert analysis
  enabled: false
  
  # Obfuscation level before sending to LLM
  # - minimal: Only secrets/credentials obfuscated
  # - standard: IPs, hostnames, users, paths obfuscated (recommended)
  # - paranoid: Everything except alert type and priority
  obfuscation_level: standard
  
  # LLM Provider: ollama, openai, anthropic (env: LLM_PROVIDER)
  provider: ${LLM_PROVIDER:-ollama}
  
  # Ollama (local) - recommended for privacy
  ollama:
    url: ${OLLAMA_URL:-http://localhost:11434}
    model: ${OLLAMA_MODEL:-llama3.1:8b}
    # Alternative models: mistral, mixtral, qwen2.5
  
  # OpenAI (cloud) - requires API key
  openai:
    api_key: ${OPENAI_API_KEY}
    model: ${OPENAI_MODEL:-gpt-4o-mini}
    # Alternative: gpt-4o for better quality
  
  # Anthropic (cloud) - requires API key  
  anthropic:
    api_key: ${ANTHROPIC_API_KEY}
    model: ${ANTHROPIC_MODEL:-claude-3-haiku-20240307}
    # Alternative: claude-sonnet-4-20250514 for better quality

# Storage backend: loki or vm (auto-detected from STACK env var)
storage:
  backend: ${STACK:-vm}

# Loki connection (used when STACK=grafana)
loki:
  url: ${LOKI_URL:-http://sib-loki:3100}

# VictoriaLogs connection (used when STACK=vm)
victorialogs:
  url: ${VICTORIALOGS_URL:-http://sib-victorialogs:9428}
